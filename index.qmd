---
title: "Deploying Models into Production with Vetiver"
author: "Myles Mitchell @ Jumping Rivers"
format:
  jrSlides-revealjs:
    code-link: true
    width: 1600
    height: 900
    embed-resources: true
---

# Before we start...

## Who am I?

:::: {.columns}

::: {.column width="60%"}
:::{.incremental}
- Data Scientist @ Jumping Rivers:

  - Python & R support for clients.

  - Teach courses in programming, SQL, ML.

- Enjoy the outdoors & travel.

- Organise North East & Leeds data science meetups.
:::
:::

::: {.column width="40%"}
![](img/myles.jpg)
:::

::::

## Talk plan

:::{.incremental}
* Beginners guide to MLOps

* Using free / open source software (as much as possible)

* Walk through the steps of building and deploying a model

* MLOps tips & tricks
:::

# Some context...

## Jumping Rivers

:::{.columns}
:::{.column width="58%"}
[‚Üó jumpingrivers.com](https://www.jumpingrivers.com/) &nbsp; [ùïè @jumping_uk](https://twitter.com/jumping_uk)

- Machine learning
- Dashboard development
- R packages and APIs
- Data pipelines
- Code review

<center>
![](img/R_logo.png){width="23%"}  &nbsp; ![](img/posit.png){width="19%"} &nbsp; ![](img/stan.png){width="18%"}  &nbsp; ![](img/python.png){width="18%"}
</center>
:::
:::{.column width="42%"}
<center>
![](img/jr-logo.png)
</center>
:::
:::

## Posit

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
* Formerly RStudio

* JR is an official partner and assists clients with:

  * **Posit Connect** - host apps and APIs
  * **Posit Workbench** - running code in the cloud
  * **Posit Package Manager** - R / Python package management
:::
:::
:::{.column width="40%"}
<center>
![](img/posit.png)
</center>
:::
:::

## Posit frameworks

:::{.columns}
:::{.column width="50%"}
:::{.incremental}
* Posit maintains free and open source frameworks including:

  * **Quarto** - automated reporting
  * **Shiny** - interactive web apps
  * **Vetiver** - MLOps framework
  
* Compatible with R, Python and more!
:::
:::
:::{.column width="50%"}
<center>
![](img/quarto.png){width="50%"}
![](img/shiny.png){width="50%"}
![](img/vetiver-logo.png){width="40%"}
</center>
:::
:::

# What is MLOps?

## Typical data science workflow

<center>
![](img/ds-workflow.png){width="80%"}
</center>

* Data is imported and tidied.
* Cycle of data transformation, visualisation and modelling.
* Results are communicated to an external audience.

## From Classical Stats to Machine Learning

:::{.columns}
:::{.column width="80%"}
:::{.incremental}
* Classical statistical modelling prioritises understanding the *system* behind the data.
* By contrast, machine learning tends to prioritise *prediction*.
* As data grows we retrain our ML models to optimise predictive power.
* A goal of MLOps is to streamline this cycle.
:::
:::
:::

## MLOps: Machine Learning Operations

<center>
![](img/mlops-flow.png){width="100%"}
</center>

* Framework to continuously build, deploy and maintain ML models.
* Encapsulates the "full stack" from data acquisition to model deployment.
* Includes **versioning**, **deployment** and **monitoring**.

## MLOps frameworks

* Amazon SageMaker
* Google Cloud Platform
* Kubeflow (ML toolkit for Kubernetes)
* Vetiver by Posit (free to install, nice for beginners)
* And the list goes on...

<center>
![](img/sagemaker-logo.jpg){width="19%"}  &nbsp; ![](img/azure-logo.png){width="20%"} &nbsp; ![](img/gcp-logo.png){width="20%"}  &nbsp; ![](img/vetiver-logo.png){width="17%"}

## Vetiver

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
* Integrates with popular ML libraries in R and Python.
* Fluent tooling to version, deploy and monitor a trained model.
* Deploy to a cloud service or to the localhost.
:::
:::
:::{.column width="40%"}
<center>
![](img/posit-logo.png)
![](img/vetiver-logo.png){width="60%"}
</center>
:::
:::

# Let's build an MLOps stack!

## Data

:::{.incremental}
*   Palmer Penguins dataset:

    ```{r}
    #| echo: true
    #| code-line-numbers: 1,2,3
    library("palmerpenguins")

    names(penguins)
    ```

*   Let's predict **species** using flipper length, body mass and island!
:::

---

```{r}
#| echo: false
#| message: false
#| output-location: slide
#| fig-cap: "Palmer Penguin dataset"
#| fig-alt: "Scatter plot showing positive relationship between penguin flipper length and penguin body mass. The data points are coloured based on species and shaped based on island. The Gentoo penguins tend to have higher body mass and flipper length than Adelie and Chinstrap."
library("ggplot2")

ggplot(penguins, aes(flipper_length_mm, body_mass_g)) +
  geom_point(aes(colour = species, shape = island)) +
  theme_minimal() +
  xlab("Flipper Length(mm)") +
  ylab("Body Mass(g)") +
  viridis::scale_colour_viridis(discrete = TRUE)
```

## Data tidying

*   Using {tidyr} and {rsample}:

    ```{r}
    #| echo: true
    #| code-line-numbers: 1,2,3,4,5,6,7,8,9|1,2|4,5,6,7|8,9
    # Drop missing data
    penguins_data = tidyr::drop_na(penguins)
    
    # Split into train and test sets
    penguins_split = rsample::initial_split(
      penguins_data, prop = 0.8
    )
    train_data = rsample::training(penguins_split)
    test_data = rsample::testing(penguins_split)
    ```

## Modelling

* Let's set up the model recipe in {tidymodels}:

```{r}
#| echo: true
#| code-line-numbers: 1,2,3,4,5,6,7,8|3,4,5,6|7|8
library("tidymodels")

model = recipe(
  species ~ island + flipper_length_mm + body_mass_g,
  data = train_data
) |>
  workflow(nearest_neighbor(mode = "classification")) |>
  fit(train_data)
```

## Model testing

* Our model object can now be used to predict `species`{.r}:

```{r}
#| echo: true
#| code-line-numbers: 1,2,3,4,5,6,7,8|1|3,4,5,6,7,8
model_pred = predict(model, test_data)

# Accuracy for unseen test data
mean(
  model_pred$.pred_class == as.character(
    test_data$species
  )
)
```

## Enter Vetiver!

:::{.columns}
:::{.column width="70%"}
:::{.incremental}
*   Convert our {tidymodels} model to a {vetiver} model:

    ```{r}
    #| echo: true
    #| code-line-numbers: 1,2,3,4,5,6
    v_model = vetiver::vetiver_model(
      model,
      model_name = "k-nn",
      description = "penguin-species"
    )
    v_model
    ```

*   Contains all the info needed to version, store and deploy our model!
:::
:::
:::{.column width="30%"}
<center>
![](img/vetiver-logo.png){width="80%"}
</center>
:::
:::

## Model versioning

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
*   Use {pins} to store R or Python objects for reuse later.

*   Store pins using "boards" including Posit Connect, Amazon S3 or even Google
    drive!

*   Storing in a temporary directory:

    ```{r}
    #| echo: true
    #| code-line-numbers: 1,2,3,4,5|1,2,3|4,5
    model_board = pins::board_temp(
      versioned = TRUE
    )
    model_board |>
      vetiver::vetiver_pin_write(v_model)
    ```
:::
:::
:::{.column width="40%"}
<center>
![](img/pins-logo.png){width="80%"}
</center>
:::
:::

## Retrieving a model

:::{.incremental}
*   Retrieve a model

    ```{r}
    #| echo: true
    model_board |> vetiver::vetiver_pin_read("k-nn")
    ```

*   Inspect the stored versions

    ```{r}
    #| echo: true
    model_board |> pins::pin_versions("k-nn")
    ```
:::

## Model deployment

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
* We deploy models as APIs which take input data and send back model predictions.

* APIs can be hosted at public endpoints on the web.

* We can run them on the localhost (during testing / development).

* {vetiver} uses {plumber} to create a model API.
:::
:::

:::{.column width="40%"}
<center>
![](img/plumber-logo.png){width="80%"}
</center>
:::
:::

## Deploying locally

:::{.incremental}
*   {vetiver} and {plumber} support local deployment:

    ```{r}
    #| echo: true
    #| eval: false
    #| code-line-numbers: 1,2,3|2
    plumber::pr() |>
      vetiver::vetiver_api(v_model) |>
      plumber::pr_run()
    ```

*   Query the API via a simple dashboard or the command line.

*   Great for beginners to MLOps and APIs!
:::

---

<center>
![](img/api.png){width="100%"}
</center>

## Deploying to Connect

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
*   Vetiver integrates nicely with Posit Connect:

    ```r
    vetiver::vetiver_deploy_rsconnect(
      board = model_board, "k-nn"
    )
    ```
    
*   Easier / quicker if pinned model is on Connect.

*   We can also publish to Amazon SageMaker using
    `vetiver_deploy_sagemaker()`{.r}
:::
:::
:::{.column width="40%"}
<center>
![](img/posit.png){width="60%"}
![](img/sagemaker-logo.jpg){width="60%"}
</center>
:::
:::

## Deploying to other cloud platforms

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
*   We start by preparing a **Docker container**:

    ```{r}
    #| echo: true
    #| eval: false
    #| code-line-numbers: 1,2,3
    vetiver::vetiver_prepare_docker(
      model_board,
      "k-nn"
    )
    ```

*   This command:

    * Lists R depedencies with {renv}

    * Stores the {plumber} API code in `plumber.R`

    * Generates a **Dockerfile**
:::
:::
:::{.column width="40%"}
<center>
![](img/docker-logo.png)
</center>
:::
:::

## Dockerfiles

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
* Our Dockerfile contains a series of commands to:

  * Install the system libraries (Windows|Mac|Linux).

  * Set the R version and install the required R packages.

  * Run the API in the deployment environment.

* Use automated CI/CD to build the API in the cloud environment.
:::


:::

:::{.column width="40%"}
<center>
![](img/docker-logo.png)
</center>
:::
:::

## Model monitoring

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
*   As our data grows, run regular checks of model performance.

*   Monitor key model metrics over time (requires a `date`{.r} column):

    ```{r}
    #| echo: true
    #| eval: false
    #| code-line-numbers: 1,2,3,4,5,6,7|2,3|4,5,6,7
    metrics =
      augment(v_model,
              new_data = new_penguins) |>
      vetiver_compute_metrics(date,
                              "year",
                              species,
                              .pred)
    ```
:::
:::
:::

## Model drift

:::{.incremental}
*   Store our metrics in our {pins} board:

    ```{r}
    #| echo: true
    #| eval: false
    model_board |>
      vetiver_pin_metrics(metrics, "k-nn_metrics")
    ```

*   Plot the metrics:

    ```{r}
    #| echo: true
    #| eval: false
    vetiver::vetiver_plot_metrics(metrics)
    ```

*   Over time we may notice a drop in performance...
:::

---

<center>
![](img/model_drift.png){width="70%"}
</center>

## Model drift

:::{.incremental}
* Model performance may *drift* as the data evolves...
  * *Data* drift: statistical distribution of input feature changes.
  * *Concept* drift: relationship between target and input variables changes.

* The context in which your model was trained matters!
:::

<center>
![](img/penguins.jpg)
</center>


## Aside: What about Python?

:::{.incremental}
* Vetiver is available for both Python and R!

* In Python you would use Python ML libraries rather than {tidymodels}
  * scikit learn
  * PyTorch
  * XGBoost
  * statsmodels

* Vetiver documentation: [vetiver.posit.co](https://vetiver.posit.co/)
:::

# MLOps tips & tricks

## Data

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
* Move from large CSVs to more efficient formats like Parquet and Arrow.
* Tools like Apache Spark can speed up data processing.
* Add a data validation step.
* Version your data.
* Your preferred ML platform probably has built-in tools for data wrangling.
:::
:::

:::{.column width="40%"}
<center>
![](img/parquet-logo.png)
</center>
:::
:::

## Modelling

:::{.columns}
:::{.column width=60%}
:::{.incremental}
* Consider creating an R package to encourage proper documentation, testing and dependency management.
* Consider auto-ML tools like H2O.ai and SageMaker Autopilot for model selection.
* Version and store your models for reuse later.
:::
:::

:::{.column width="40%"}
<center>
![](img/tidyverse-logo.png){width="70%"}
![](img/h2o-logo.png){width="60%"}
</center>
:::
:::

## Deployment

:::{.columns}
:::{.column width="60%"}
:::{.incremental}
* Try deploying locally to check that your model API works as expected.
* Use environment managers like {renv} to store model dependencies.
* Use containers like Docker to bundle model source code with dependencies.
:::
:::

:::{.column width="40%"}
<center>
![](img/renv-logo.png){width="60%"}
![](img/docker-logo.png){width="80%"}
</center>
:::
:::

## Cost considerations

:::{.incremental}
* Some cloud platforms offer free trials (e.g., SageMaker 2-month trial).
* May be cheaper if you're already invested in a particular cloud platform
  * Data services
  * App deployment
* Costs can rise depending on computational resources consumed.
* Model building and deployment use different environments.
:::

## Benefits of an MLOps workflow

:::{.incremental}
* Retraining and redeployment can happen at the click of a button.

* Encourages good practices like model versioning.

* Reduces human error.

* Well defined and reproducible.

* **Consider whether it is worth the cost/effort before starting.**
:::

## Thanks for listening!

:::{style="font-size: 45px;"}
:::{.columns}
:::{.column width="45%"}
* Slides: [bit.ly/2024-nicd-mlops](https://bit.ly/2024-nicd-mlops)
* Vetiver docs: [vetiver.posit.co](https://vetiver.posit.co/)
* Jumping Rivers courses: [jumpingrivers.com/training/](https://www.jumpingrivers.com/training/)
* Jumping Rivers blog: [jumpingrivers.com/blog/](https://www.jumpingrivers.com/blog/)
:::
:::{.column width="55%"}
<center>
![](img/jr-logo.png)
</center>
:::
:::
:::
